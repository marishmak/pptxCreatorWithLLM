{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "igqjd8__eHOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "LtwmOd7CVSdU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai python-pptx PyPDF2 pyTelegramBotAPI qdrant-client\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "K_a3Aa7vbQG-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import csv\n",
        "import json\n",
        "import telebot\n",
        "from telebot import types\n",
        "import os\n",
        "import getpass\n",
        "import PyPDF2\n",
        "import re\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import models, QdrantClient"
      ],
      "metadata": {
        "id": "6S8sFFTqEyFs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "gj8p0CfamEoD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QDRANT_API = userdata.get('QDRANT-API')\n",
        "\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://2f1c4ffe-c4fe-4f27-a1ad-85acebc21ffe.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=QDRANT_API,\n",
        ")"
      ],
      "metadata": {
        "id": "ANw6y7Hr9rLW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presentation creation"
      ],
      "metadata": {
        "id": "bqThGayAvt73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the embedding model from SentenceTransformers\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "axEUWgPpiIuZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_content(prompt: str) -> str:\n",
        "\n",
        "  try:\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text if hasattr(response, 'text') else \"Sorry, I couldn't generate a response.\"\n",
        "  except Exception as e:\n",
        "    return f\"There was an error generating the response: {str(e)}\"\n",
        "\n",
        "  return \"Sorry, I couldn't generate a response.\"\n",
        "\n",
        "\n",
        "def generate_prompt_for_db(text):\n",
        "  prompt_input = f\"\"\"\n",
        "You are an assistant with artificial intelligence who corrects this text, preprocesses it so that the related words are separated by a space, turns it into a coherent text, shortens it a little and outputs it convenient for explaining the topic in the presentation.\n",
        "Text:\n",
        "{text}\n",
        "Please provide output only in this format without anything else.\n",
        "Format example:\n",
        "Title:: Some title\n",
        "Text:: Some text from given text\n",
        "\"\"\"\n",
        "  content = generate_content(prompt_input)\n",
        "\n",
        "  return content\n"
      ],
      "metadata": {
        "id": "HTcTmQn0sfj9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def database_replenishment(content, documents):\n",
        "  if 'Title:: ' in content:\n",
        "    content = content[8:].split('Title:: ')\n",
        "\n",
        "    title = ''\n",
        "    text=content\n",
        "\n",
        "    for i in content:\n",
        "      i = i.split('\\nText:: ')\n",
        "      if len(i)==2:\n",
        "        title = i[0]\n",
        "        text = i[1]\n",
        "\n",
        "      # Add page as documents to the vector database\n",
        "        documents.append({ \"title\": title, \"text\": text})\n",
        "  else:\n",
        "    documents.append({ \"title\": \"Some text\", \"text\": content})\n",
        "  return documents\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, message, msg, COLLECTION_NAME):\n",
        "  # removing special characters and tags from the documents\n",
        "  pattern=r\"[^\\w]\"\n",
        "  length=0\n",
        "  documents=[]\n",
        "\n",
        "  with open(pdf_path, 'rb') as pdf_file:\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "    for i, page in enumerate(pdf_reader.pages):\n",
        "\n",
        "      text = page.extract_text()\n",
        "\n",
        "      if i%10==0:\n",
        "        bot.edit_message_text(chat_id = message.chat.id, message_id = msg.message_id, text = f\"Please wait while the file is being written to the database. It may take some time.\\nDone...{round(i/len(pdf_reader.pages)*100, 2)}%\")\n",
        "\n",
        "      if text:\n",
        "\n",
        "        text=re.sub(pattern, \" \", text)\n",
        "        mark=True\n",
        "\n",
        "        try:\n",
        "          for i in range(5):\n",
        "            content = generate_prompt_for_db(text)\n",
        "\n",
        "            if 'error generating the response:' not in content and \"couldn't generate a response.\"  not in content:\n",
        "              documents = database_replenishment(str(content), documents)\n",
        "              mark=False\n",
        "              break\n",
        "\n",
        "          if mark:\n",
        "            documents = database_replenishment(str(text), documents)\n",
        "          mark=True\n",
        "\n",
        "        except Exception as e:\n",
        "          print('Error:', e)\n",
        "          documents = database_replenishment(str(text), documents)\n",
        "\n",
        "  qdrant_client.upload_points(\n",
        "      collection_name=COLLECTION_NAME,\n",
        "      points=[\n",
        "          models.PointStruct(\n",
        "              id=idx, vector=embedder.encode(doc[\"text\"]).tolist(), payload=doc\n",
        "          )\n",
        "          for idx, doc in enumerate(documents)\n",
        "      ],\n",
        "  )\n",
        "  bot.edit_message_text(chat_id = message.chat.id, message_id = msg.message_id, text = \"Please wait while the file is being written to the database. It may take some time.\\nDone!\")\n",
        "  print('Successful')\n",
        "  return [i['title'] for i in documents]\n"
      ],
      "metadata": {
        "id": "lXNn0u-JgqDx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_quastion_for_PP_code(topics, text, name):\n",
        "  prompt_input = f\"\"\"\n",
        "You are an assistant with artificial intelligence who generates a code for creation a PowerPoint presentation using python-pptx library based on given text. Name the pptx file like this:{name}\n",
        "Please provide output only in code format without anything else. Note that 'SlideShapes' object has no attribute 'subtitle'. Please note that the topics and texts must be spelled out explicitly (for example, text = 'Some text...')\n",
        "List of topics:\n",
        "{topics}\n",
        "List of texts from book:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "  content = generate_content(prompt_input)\n",
        "  return content[10:-4]\n",
        "\n",
        "\n",
        "def generate_topics_for_section(text, titles):\n",
        "  prompt_input = f\"\"\"\n",
        "You are an artificial intelligence assistant who sets the topics that should be included in this section of the course. Create themes based on existing titles extracted from the database.\n",
        "Please provide output only in code format without anything else.\n",
        "Section:\n",
        "{text}\n",
        "Titles from database:\n",
        "{titles}\n",
        "\n",
        "Expected output format:\n",
        "topic1\n",
        "topic2\n",
        "...\n",
        "\"\"\"\n",
        "\n",
        "  content = generate_content(prompt_input)[4:-4]\n",
        "  content = content.split('\\n')\n",
        "  return content\n",
        "\n",
        "\n",
        "def extract_section_topics_from_qdrant(section, COLLECTION_NAME, titles):\n",
        "  print('Section:', section)\n",
        "  while 1:\n",
        "    topics = generate_topics_for_section(section, titles)\n",
        "\n",
        "    if 'error generating the response:' not in topics and \"couldn't generate a response.\"  not in topics:\n",
        "      break\n",
        "\n",
        "  print('Topics generated:', topics)\n",
        "\n",
        "  output=[]\n",
        "  test=[]\n",
        "\n",
        "  for query in section:\n",
        "\n",
        "    # Retrieve relevant documents from ChromaDB\n",
        "    try:\n",
        "      results = qdrant_client.query_points(\n",
        "          collection_name=COLLECTION_NAME,\n",
        "          query=embedder.encode(query).tolist(),\n",
        "          limit=1,\n",
        "      ).points\n",
        "    except Exception as e:\n",
        "      print(f\"Error occured in data extraction from db: {e}\")\n",
        "      results={}\n",
        "\n",
        "\n",
        "    for result in results:\n",
        "    # Extract content from the results\n",
        "      retrieved_docs = result.payload['text']\n",
        "      test.append(result.score)\n",
        "\n",
        "    output.append(retrieved_docs)\n",
        "\n",
        "  meanMentric=sum(test)/len(test)\n",
        "  print('Automated Benchmark test RAG:', meanMentric)\n",
        "\n",
        "\n",
        "  return output, topics\n",
        "\n",
        "\n",
        "\n",
        "def topics2code(sections, docs):\n",
        "  file_pptx = []\n",
        "  length = 0\n",
        "\n",
        "  for i, section in enumerate(sections):\n",
        "    print('Topics:', section)\n",
        "    print('Docs:', docs[i])\n",
        "\n",
        "    while len(file_pptx)<=length:\n",
        "\n",
        "      code=generate_quastion_for_PP_code(section, docs[i], f\"Lecture{i+1}.pptx\")\n",
        "\n",
        "      while 'error generating the response' in code:\n",
        "        code=generate_quastion_for_PP_code(section, docs[i], f\"Lecture{i+1}.pptx\")\n",
        "\n",
        "\n",
        "      try:\n",
        "        exec(code)\n",
        "        file_pptx.append(f\"Lecture{i+1}.pptx\")\n",
        "      except Exception as e:\n",
        "        print('Error:', e)\n",
        "\n",
        "    length+=1\n",
        "\n",
        "\n",
        "  return file_pptx\n",
        "\n"
      ],
      "metadata": {
        "id": "YHxRG_Qaw99B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TELEGRAM_API = userdata.get('pptx_telegram_API')\n",
        "bot = telebot.TeleBot(TELEGRAM_API)\n",
        "global titles\n",
        "global COLLECTION_NAME\n",
        "titles=[]\n",
        "\n",
        "for i in qdrant_client.get_collections().collections:\n",
        "  COLLECTION_NAME=i.name\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['start', 'help'])\n",
        "def send_welcome(message):\n",
        "\n",
        "    if len(qdrant_client.get_collections().collections)==0:\n",
        "      bot.send_message(message.chat.id, \"Hi, this is a pptx_creator_bot for creating presentations based on the pdf version of the course book and lecture plan.\\nTo start creating presentations, send a pdf file with the course materials.\")\n",
        "\n",
        "    else:\n",
        "      bot.send_message(message.chat.id, \"Hi, this is a pptx_creator_bot for creating presentations based on the pdf version of the course book and lecture plan.\\nYou already have a pdf file in the database.\\nTo continue working with the file, send topics for creating presentations, and to replace the file with another one, send a new pdf file with course materials, but the data from the previous file will be deleted.\")\n",
        "\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['document'])\n",
        "def handle_pdf(message):\n",
        "    if len(qdrant_client.get_collections().collections)!=0:\n",
        "      qdrant_client.delete_collection(collection_name=f\"{COLLECTION_NAME}\")\n",
        "    try:\n",
        "\n",
        "\n",
        "        # Download the PDF file\n",
        "        file_info = bot.get_file(message.document.file_id)\n",
        "        downloaded_file = bot.download_file(file_info.file_path)\n",
        "        COLLECTION_NAME = str(message.document.file_id)\n",
        "\n",
        "        qdrant_client.create_collection(\n",
        "            collection_name=COLLECTION_NAME,\n",
        "            vectors_config=models.VectorParams(\n",
        "                size=embedder.get_sentence_embedding_dimension(),\n",
        "                distance=models.Distance.COSINE,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        pdf_path = 'book.pdf'\n",
        "        # Save the PDF file temporarily\n",
        "        with open(pdf_path, 'wb') as new_file:\n",
        "            new_file.write(downloaded_file)\n",
        "\n",
        "        # Extract text from the PDF\n",
        "        msg = bot.send_message(message.chat.id, \"Please wait while the file is being written to the database. It may take some time.\")\n",
        "\n",
        "        titles = extract_text_from_pdf(pdf_path, message, msg, COLLECTION_NAME)\n",
        "        os.remove('book.pdf')\n",
        "\n",
        "\n",
        "        # Wait for the user to send text\n",
        "        bot.reply_to(message, f\"{len(titles)} documents have been successfully saved in the database.\")\n",
        "        bot.reply_to(message, \"Please provide me the course content by highlighting each lecture in a separate line so that I can include it in pptx.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        bot.reply_to(message, f\"Error: {e}\")\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def handle_text(message):\n",
        "\n",
        "  if len(qdrant_client.get_collections().collections)==0:\n",
        "    bot.reply_to(message, \"The database does not contain data about the book, so first send the pdf file, and then enter the topics of the lectures.\")\n",
        "  else:\n",
        "\n",
        "    try:\n",
        "        # Get the text from the user\n",
        "        sections = message.text\n",
        "        bot.reply_to(message, \"Please wait until the bot sends you the pptx files.\")\n",
        "        sections = sections.split('\\n')\n",
        "\n",
        "        topics=[]\n",
        "        docs = []\n",
        "\n",
        "        # Create a PPTX file\n",
        "        for section in sections:\n",
        "          outputs, queries = extract_section_topics_from_qdrant(section, COLLECTION_NAME, titles)\n",
        "          topics.append(queries)\n",
        "          docs.append(outputs)\n",
        "\n",
        "        presents = topics2code(topics, docs)\n",
        "\n",
        "        # Send the PPTX file back to the user\n",
        "        for i in presents:\n",
        "          with open(i, 'rb') as pptx_file:\n",
        "              bot.send_document(message.chat.id, pptx_file)\n",
        "\n",
        "        for i in presents:\n",
        "          os.remove(i)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        bot.reply_to(message, f\"Error: {e}\")\n",
        "\n",
        "\n",
        "# Run the bot\n",
        "bot.polling(non_stop=True, interval=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "ZxB9a9UJBDX5",
        "outputId": "0190c877-f663-43b5-db40-2632afc91e4d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section: Representation of images and videos (Computer representation, Rescaling/manipulating images)\n",
            "Topics generated: ['Image Representation', 'Pixel-based representations', 'Vector-based representations', 'Image Compression', 'Resizing and Scaling', 'Image Manipulation', 'Color Space Transformations', 'Video Representation', 'Frame-based representation', 'Video Compression', 'Motion estimation']\n",
            "Automated Benchmark test RAG: 0.17027092663043483\n",
            "Section: Image Classification (Loss Functions, Backpropagation)\n",
            "Topics generated: ['Loss Functions for Image Classification', 'Backpropagation for Image Classification']\n",
            "Automated Benchmark test RAG: 0.17124105944444445\n",
            "Section: Neural Networks (Training)\n",
            "Topics generated: ['Introduction to Neural Network Training', 'Loss Functions and Optimization', 'Gradient Descent and its Variants', 'Backpropagation Algorithm', 'Regularization Techniques', 'Overfitting and Underfitting', 'Hyperparameter Tuning', 'Batch, Mini-batch, and Stochastic Gradient Descent', 'Learning Rate Scheduling', 'Early Stopping', 'Data Augmentation', 'Transfer Learning', 'Fine-Tuning Pre-trained Models', 'Model Evaluation and Metrics']\n",
            "Automated Benchmark test RAG: 0.17013089346153848\n",
            "Section: Convolutional Neural Networks  (Training, Architectures)\n",
            "Topics generated: ['olutional Neural Networks: Training', 'Convolutional Neural Networks: Architectures ', '`']\n",
            "Automated Benchmark test RAG: 0.1731698625\n",
            "Section: Recurrent Neural Networks (Training, Architectures)\n",
            "Topics generated: ['Recurrent Neural Network Training', 'Recurrent Neural Network Architectures']\n",
            "Automated Benchmark test RAG: 0.17141215901960782\n",
            "Section: Image Segmentation and object detection (Techniques)\n",
            "Topics generated: ['Image Segmentation Techniques', 'Object Detection Techniques', 'Deep Learning for Image Segmentation', 'Deep Learning for Object Detection', 'Traditional Image Segmentation Methods', 'Traditional Object Detection Methods', 'Semantic Segmentation', 'Instance Segmentation', 'Panoptic Segmentation', 'Region-based Convolutional Neural Networks (R-CNN)', 'You Only Look Once (YOLO)', 'Single Shot MultiBox Detector (SSD)', 'Image Segmentation Evaluation Metrics', 'Object Detection Evaluation Metrics', 'Applications of Image Segmentation', 'Applications of Object Detection']\n",
            "Automated Benchmark test RAG: 0.17007039884615383\n",
            "Topics: ['Image Representation', 'Pixel-based representations', 'Vector-based representations', 'Image Compression', 'Resizing and Scaling', 'Image Manipulation', 'Color Space Transformations', 'Video Representation', 'Frame-based representation', 'Video Compression', 'Motion estimation']\n",
            "Docs: ['Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Specificity, also known as the true negative rate, is the percentage of negative classifications that are correct. The F-measure is a weighted average of precision and recall, allowing for varying emphasis on each metric. The F1-measure gives equal weight to precision and recall. The F2-measure prioritizes recall, while the F0.5-measure prioritizes precision.  Figure 8.27 demonstrates these metrics in a template matching example, showing precision, recall, and F1 values for a range of thresholds.  Specificity and accuracy are approximately 1.0 for all threshold values. A threshold value of 0.992 would result in perfect performance. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"Dilation is a morphological operation that expands the boundaries of objects in a binary image. Using a 3x3 isotropic structuring element, dilation fills in holes and joins close objects. In OpenCV, dilation is implemented using the `dilate` function. Changing the structuring element size, for example, to a 5x5 isotropic element, affects the dilation outcome. Dilation increases the size of objects by adding points to the object's set, effectively filling small holes and gaps. Erosion, another morphological operation, contracts object boundaries, the opposite of dilation.  \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n']\n",
            "Error: name 'topics' is not defined\n",
            "Topics: ['Loss Functions for Image Classification', 'Backpropagation for Image Classification']\n",
            "Docs: ['The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'Specificity, also known as the true negative rate, is the percentage of negative classifications that are correct. The F-measure is a weighted average of precision and recall, allowing for varying emphasis on each metric. The F1-measure gives equal weight to precision and recall. The F2-measure prioritizes recall, while the F0.5-measure prioritizes precision.  Figure 8.27 demonstrates these metrics in a template matching example, showing precision, recall, and F1 values for a range of thresholds.  Specificity and accuracy are approximately 1.0 for all threshold values. A threshold value of 0.992 would result in perfect performance. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'Specificity, also known as the true negative rate, is the percentage of negative classifications that are correct. The F-measure is a weighted average of precision and recall, allowing for varying emphasis on each metric. The F1-measure gives equal weight to precision and recall. The F2-measure prioritizes recall, while the F0.5-measure prioritizes precision.  Figure 8.27 demonstrates these metrics in a template matching example, showing precision, recall, and F1 values for a range of thresholds.  Specificity and accuracy are approximately 1.0 for all threshold values. A threshold value of 0.992 would result in perfect performance. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", '116 A Practical IntroductiontoComputer Vision with OpenCV   Figure 7 1 The Aperture Problem exemplifies the problem of local processing  In the images shown weareconsideringjustthepixelsinsidetheholeinthegreyarea Twoimagesareshownfromasynthetic imagesequence left and centre withtheedgepointsmarkedingreen alongwithsomeofthepossible linkages forone of the  green  edge points  right  Figure 7 2 Two images from an image sequence  left  and  centre  with the edge points marked in green  the only reasonable linkage for the corner  right  assuming that the same feature has remained visible Figure 7 3 Corners features detected from Harris  centre left   FAST  centre right   SIFT  right  from a greyscale version of theimage onthe left', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"K-means clustering is an unsupervised learning technique used for image segmentation. It involves determining cluster centers and assigning labels to each pixel based on its proximity to these centers.  The process utilizes the following:\\n\\n- **K:** The number of desired clusters.\\n- **Samples:** The image pixels.\\n- **Labels:** Cluster assignments for each pixel.\\n- **Centres:** Cluster center locations. \\n- **TermCriteria:** Termination criteria (iterations and/or epsilon) for the algorithm.\\n\\nAfter clustering, the cluster centers and labels are used to populate a result image. The image is processed pixel-by-pixel, and each pixel's color is determined by the color of its assigned cluster center. \\n\\nUnsupervised learning, like k-means clustering, relies on inherent patterns within the data, enabling similar pixels to be grouped together without explicit training labels. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n']\n",
            "Topics: ['Introduction to Neural Network Training', 'Loss Functions and Optimization', 'Gradient Descent and its Variants', 'Backpropagation Algorithm', 'Regularization Techniques', 'Overfitting and Underfitting', 'Hyperparameter Tuning', 'Batch, Mini-batch, and Stochastic Gradient Descent', 'Learning Rate Scheduling', 'Early Stopping', 'Data Augmentation', 'Transfer Learning', 'Fine-Tuning Pre-trained Models', 'Model Evaluation and Metrics']\n",
            "Docs: [\"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', '152 A Practical IntroductiontoComputer Vision with OpenCV This requires an estimation of the probability density function over the feature space for this class  i e  p x Wr   together with the relative probability that objects of this class P Wr  willoccur  The mean loss function  thefunction with respect to which theclassifier is optimal  is  J q    x  s 1  R𝜆 d x q  Ws p x Ws P Ws dx where𝜆 Wr Ws    0if r s 1otherwise 8 15  where rd x q isthedecisionruleforselectingaclassbasedonapattern xandtheweightsforeach featurefor each class r𝜆 Wr Ws givesthelossincurredifapatternwhichshouldbeclassifiedas Wsisinsteadclas  sifiedasWr Toachieveaminimumlossthisissettoafixedlossof1foranymisclassification and alossof 0 for acorrect classification rp x Ws  is theprobability of the patternx given theclass Ws rP Ws  is the probability of occurrence of the class Ws  8 3 3 4 Classifier Training Thequalityofdecisionruleforaprobabilisticclassifierfundamentallydependsonthequality of the probability density functions and relative class probabilities on which it is based  The quality of these probabilities depends largely on upon the quality and size of the training set  Thissetmustberepresentativeofallpossibleposesofallpossibleobjects i e thesetmustbe inductive  effectivelyallowingtheclassifiertocorrectlyrecognisepresentationsoftheobjects that ithas never seen before  Itisnotreallypossibletodefinetherequiredtrainingsetsizeinadvance soinsteadthesize isgraduallyincreaseduntilthediscriminationfunctionsareestimatedwithsufficientaccuracy  The probabilities have to be learnt and this can be done in a supervised manner  where each sample in the training set is accompanied by a class specification   This allows us to automatically select the features which provide the best discrimination for the samples in the training set  The probabilities can also be learnt in an unsupervised manner where the samples are unclassifiedandpotentialclassesareidentifiedbylocatingclustersinfeaturespace However  in thiscase itis hard to automatically select the appropriate features  8 3 3 5 Example Using Real Data To finish this section  we illustrate the power of this approach with recognition from real imagery taken in an unconstrained outdoor environment  See Figure 8 19  8 4 Cascadeof Haar Classifiers This section looks at a specific advanced technique for real time object pattern recognition as presented in two significant research papers   Viola  2001  and  Lienhart  2002   See', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"K-means clustering is an unsupervised learning technique used for image segmentation. It involves determining cluster centers and assigning labels to each pixel based on its proximity to these centers.  The process utilizes the following:\\n\\n- **K:** The number of desired clusters.\\n- **Samples:** The image pixels.\\n- **Labels:** Cluster assignments for each pixel.\\n- **Centres:** Cluster center locations. \\n- **TermCriteria:** Termination criteria (iterations and/or epsilon) for the algorithm.\\n\\nAfter clustering, the cluster centers and labels are used to populate a result image. The image is processed pixel-by-pixel, and each pixel's color is determined by the color of its assigned cluster center. \\n\\nUnsupervised learning, like k-means clustering, relies on inherent patterns within the data, enabling similar pixels to be grouped together without explicit training labels. \\n\", \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n']\n",
            "Error: name 'topics' is not defined\n",
            "Topics: ['olutional Neural Networks: Training', 'Convolutional Neural Networks: Architectures ', '`']\n",
            "Docs: ['Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", \"Dilation is a morphological operation that expands the boundaries of objects in a binary image. Using a 3x3 isotropic structuring element, dilation fills in holes and joins close objects. In OpenCV, dilation is implemented using the `dilate` function. Changing the structuring element size, for example, to a 5x5 isotropic element, affects the dilation outcome. Dilation increases the size of objects by adding points to the object's set, effectively filling small holes and gaps. Erosion, another morphological operation, contracts object boundaries, the opposite of dilation.  \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', '152 A Practical IntroductiontoComputer Vision with OpenCV This requires an estimation of the probability density function over the feature space for this class  i e  p x Wr   together with the relative probability that objects of this class P Wr  willoccur  The mean loss function  thefunction with respect to which theclassifier is optimal  is  J q    x  s 1  R𝜆 d x q  Ws p x Ws P Ws dx where𝜆 Wr Ws    0if r s 1otherwise 8 15  where rd x q isthedecisionruleforselectingaclassbasedonapattern xandtheweightsforeach featurefor each class r𝜆 Wr Ws givesthelossincurredifapatternwhichshouldbeclassifiedas Wsisinsteadclas  sifiedasWr Toachieveaminimumlossthisissettoafixedlossof1foranymisclassification and alossof 0 for acorrect classification rp x Ws  is theprobability of the patternx given theclass Ws rP Ws  is the probability of occurrence of the class Ws  8 3 3 4 Classifier Training Thequalityofdecisionruleforaprobabilisticclassifierfundamentallydependsonthequality of the probability density functions and relative class probabilities on which it is based  The quality of these probabilities depends largely on upon the quality and size of the training set  Thissetmustberepresentativeofallpossibleposesofallpossibleobjects i e thesetmustbe inductive  effectivelyallowingtheclassifiertocorrectlyrecognisepresentationsoftheobjects that ithas never seen before  Itisnotreallypossibletodefinetherequiredtrainingsetsizeinadvance soinsteadthesize isgraduallyincreaseduntilthediscriminationfunctionsareestimatedwithsufficientaccuracy  The probabilities have to be learnt and this can be done in a supervised manner  where each sample in the training set is accompanied by a class specification   This allows us to automatically select the features which provide the best discrimination for the samples in the training set  The probabilities can also be learnt in an unsupervised manner where the samples are unclassifiedandpotentialclassesareidentifiedbylocatingclustersinfeaturespace However  in thiscase itis hard to automatically select the appropriate features  8 3 3 5 Example Using Real Data To finish this section  we illustrate the power of this approach with recognition from real imagery taken in an unconstrained outdoor environment  See Figure 8 19  8 4 Cascadeof Haar Classifiers This section looks at a specific advanced technique for real time object pattern recognition as presented in two significant research papers   Viola  2001  and  Lienhart  2002   See', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"K-means clustering is an unsupervised learning technique used for image segmentation. It involves determining cluster centers and assigning labels to each pixel based on its proximity to these centers.  The process utilizes the following:\\n\\n- **K:** The number of desired clusters.\\n- **Samples:** The image pixels.\\n- **Labels:** Cluster assignments for each pixel.\\n- **Centres:** Cluster center locations. \\n- **TermCriteria:** Termination criteria (iterations and/or epsilon) for the algorithm.\\n\\nAfter clustering, the cluster centers and labels are used to populate a result image. The image is processed pixel-by-pixel, and each pixel's color is determined by the color of its assigned cluster center. \\n\\nUnsupervised learning, like k-means clustering, relies on inherent patterns within the data, enabling similar pixels to be grouped together without explicit training labels. \\n\", \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"The Roberts operator utilizes two partial derivatives, often referred to as the Roberts cross operator due to their intersection. Compass edge detectors, such as Sobel and Prewitt, employ eight partial derivatives, but only two orthogonal ones are necessary. Prewitt's eight partial derivatives are defined as follows: h1, h2, h3, h4, h5, h6, h7, and h8. Typically, h1 and h3 are used. The partial derivatives can be positive or negative, represented by white (positive), black (negative), and grey (zero). \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n']\n",
            "Topics: ['Recurrent Neural Network Training', 'Recurrent Neural Network Architectures']\n",
            "Docs: ['Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', '152 A Practical IntroductiontoComputer Vision with OpenCV This requires an estimation of the probability density function over the feature space for this class  i e  p x Wr   together with the relative probability that objects of this class P Wr  willoccur  The mean loss function  thefunction with respect to which theclassifier is optimal  is  J q    x  s 1  R𝜆 d x q  Ws p x Ws P Ws dx where𝜆 Wr Ws    0if r s 1otherwise 8 15  where rd x q isthedecisionruleforselectingaclassbasedonapattern xandtheweightsforeach featurefor each class r𝜆 Wr Ws givesthelossincurredifapatternwhichshouldbeclassifiedas Wsisinsteadclas  sifiedasWr Toachieveaminimumlossthisissettoafixedlossof1foranymisclassification and alossof 0 for acorrect classification rp x Ws  is theprobability of the patternx given theclass Ws rP Ws  is the probability of occurrence of the class Ws  8 3 3 4 Classifier Training Thequalityofdecisionruleforaprobabilisticclassifierfundamentallydependsonthequality of the probability density functions and relative class probabilities on which it is based  The quality of these probabilities depends largely on upon the quality and size of the training set  Thissetmustberepresentativeofallpossibleposesofallpossibleobjects i e thesetmustbe inductive  effectivelyallowingtheclassifiertocorrectlyrecognisepresentationsoftheobjects that ithas never seen before  Itisnotreallypossibletodefinetherequiredtrainingsetsizeinadvance soinsteadthesize isgraduallyincreaseduntilthediscriminationfunctionsareestimatedwithsufficientaccuracy  The probabilities have to be learnt and this can be done in a supervised manner  where each sample in the training set is accompanied by a class specification   This allows us to automatically select the features which provide the best discrimination for the samples in the training set  The probabilities can also be learnt in an unsupervised manner where the samples are unclassifiedandpotentialclassesareidentifiedbylocatingclustersinfeaturespace However  in thiscase itis hard to automatically select the appropriate features  8 3 3 5 Example Using Real Data To finish this section  we illustrate the power of this approach with recognition from real imagery taken in an unconstrained outdoor environment  See Figure 8 19  8 4 Cascadeof Haar Classifiers This section looks at a specific advanced technique for real time object pattern recognition as presented in two significant research papers   Viola  2001  and  Lienhart  2002   See', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"K-means clustering is an unsupervised learning technique used for image segmentation. It involves determining cluster centers and assigning labels to each pixel based on its proximity to these centers.  The process utilizes the following:\\n\\n- **K:** The number of desired clusters.\\n- **Samples:** The image pixels.\\n- **Labels:** Cluster assignments for each pixel.\\n- **Centres:** Cluster center locations. \\n- **TermCriteria:** Termination criteria (iterations and/or epsilon) for the algorithm.\\n\\nAfter clustering, the cluster centers and labels are used to populate a result image. The image is processed pixel-by-pixel, and each pixel's color is determined by the color of its assigned cluster center. \\n\\nUnsupervised learning, like k-means clustering, relies on inherent patterns within the data, enabling similar pixels to be grouped together without explicit training labels. \\n\", \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"The Roberts operator utilizes two partial derivatives, often referred to as the Roberts cross operator due to their intersection. Compass edge detectors, such as Sobel and Prewitt, employ eight partial derivatives, but only two orthogonal ones are necessary. Prewitt's eight partial derivatives are defined as follows: h1, h2, h3, h4, h5, h6, h7, and h8. Typically, h1 and h3 are used. The partial derivatives can be positive or negative, represented by white (positive), black (negative), and grey (zero). \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n']\n",
            "Error: unterminated string literal (detected at line 19) (<string>, line 19)\n",
            "Topics: ['Image Segmentation Techniques', 'Object Detection Techniques', 'Deep Learning for Image Segmentation', 'Deep Learning for Object Detection', 'Traditional Image Segmentation Methods', 'Traditional Object Detection Methods', 'Semantic Segmentation', 'Instance Segmentation', 'Panoptic Segmentation', 'Region-based Convolutional Neural Networks (R-CNN)', 'You Only Look Once (YOLO)', 'Single Shot MultiBox Detector (SSD)', 'Image Segmentation Evaluation Metrics', 'Object Detection Evaluation Metrics', 'Applications of Image Segmentation', 'Applications of Object Detection']\n",
            "Docs: ['The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'The probability of an event *A* can be defined as  *P(A) = lim(n->∞) N(A)/n*, where *N(A)* is the number of times event *A* occurs in *n* trials. For example, the probability of rolling a 5 on a 6-sided die is 1/6, assuming a fair die. This probability is determined after many rolls.  If we have two events, *A* and *B*, they can be independent (e.g., *A* = \"today is Thursday\" and *B* = \"it is snowing\").  The probability of both *A* and *B* occurring is  *P(A and B) = P(A) * P(B)*. Alternatively, the events can be dependent (e.g., *A* = \"it is raining\" and *B* = \"there are clouds in the sky\"). In this case, the probability of *A* depends on whether *B* has occurred. This is expressed as *P(A and B) = P(A|B) * P(B)*, where *P(A|B)* is the conditional probability of *A* occurring given that *B* has occurred.\\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', '116 A Practical IntroductiontoComputer Vision with OpenCV   Figure 7 1 The Aperture Problem exemplifies the problem of local processing  In the images shown weareconsideringjustthepixelsinsidetheholeinthegreyarea Twoimagesareshownfromasynthetic imagesequence left and centre withtheedgepointsmarkedingreen alongwithsomeofthepossible linkages forone of the  green  edge points  right  Figure 7 2 Two images from an image sequence  left  and  centre  with the edge points marked in green  the only reasonable linkage for the corner  right  assuming that the same feature has remained visible Figure 7 3 Corners features detected from Harris  centre left   FAST  centre right   SIFT  right  from a greyscale version of theimage onthe left', 'The Roberts operator is a first-derivative edge detector. It is particularly effective with binary images, providing clean edge detection with edges being only one pixel wide.  However, its performance degrades significantly with grayscale images due to the inherent smoothness of edges in real images, making the Roberts operator susceptible to noise and inaccurate partial derivative calculations. The Roberts operator calculates edge gradients that are shifted by half a pixel along both the I and J axes. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", \"This project aims to develop a system capable of automatically recognizing road signs from single images captured by a forward-facing camera mounted on a car dashboard. The system will need to handle road signs appearing at varying sizes due to the car's movement towards them. The signs are assumed to be facing directly towards the vehicle, similar to the sample images provided. \\n\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'Counting Bicycles, Recognise Paintings, References, Index \\n', \"The Roberts operator utilizes two partial derivatives, often referred to as the Roberts cross operator due to their intersection. Compass edge detectors, such as Sobel and Prewitt, employ eight partial derivatives, but only two orthogonal ones are necessary. Prewitt's eight partial derivatives are defined as follows: h1, h2, h3, h4, h5, h6, h7, and h8. Typically, h1 and h3 are used. The partial derivatives can be positive or negative, represented by white (positive), black (negative), and grey (zero). \\n\", \"This chapter focuses on face recognition using OpenCV. We'll explore techniques like cascades, where negative sub-images are gradually removed until only the desired objects remain.  This speeds up computation as most negative images are rejected early on. The classifiers within the cascade are trained using AdaBoost, ensuring a low false negative rate. A notable example is Viola and Jones's frontal face detection cascade with 38 stages and over 6000 features. This system was trained on a vast dataset of positive and negative example images.  OpenCV supports other recognition techniques like Support Vector Machines (SVMs), which provide a similar mechanism to statistical pattern recognition. \\n\", 'The current frame, left, shows the running average with selective update, background image with α = 0.01 for background points and α = 0.0033 for foreground points, center, the detected moving pixels image, right. Compared to Figure 9.7, the car on the road on the right of the image has been effectively averaged out of the background and the car which parked is slowly being averaged into the background. Note that the background model is a grey scale image. A colour version of this model is provided in the resources accompanying the text. The original images are from the PETS 2000 dataset. Reproduced by permission of Dr. James Ferryman, University of Reading. The median is the middle value from an ordered list of values. For example, 8 is the median of 1, 1, 2, 2, 3, 3, 5, 8, 11, 12, 15, 15, 15, 18, 19. The median background image is computed by determining the median value for each pixel over the last m frames. Assuming the current frame is n, then we can compute a histogram of values for each pixel as follows: hn(i,j,p) = {k/ (n-m+1), if fk(i,j,p) = 0 otherwise}. We must then determine the median value for each pixel from these histograms. Every time a new frame is processed, we must remove the oldest value and add the new value for each pixel. This is expensive from a memory point of view as it requires us to store the m frames which are being included in the median, along with a histogram from each pixel. We must determine an appropriate value for m and typically must limit the quantisation in the histograms so that the amount of data being maintained does not become excessive, particularly where we are considering colour images. The histograms can be updated very inexpensively using a form of aging: hn(i,j,p) = {k(1-wn)/wk if fk(i,j,p) = 0 otherwise}, where w1 = 1 and wk = wk-1(1-0.05). This is an approximation to the actual histograms which works very well in practice, see Figure 9.9. We can use clever algorithms to update the median for each pixel each time a new frame is processed, as to determine the median directly from the histogram for each pixel for each frame would be extremely expensive computationally. In fact, any change in the median from frame to frame can be determined very inexpensively by simply maintaining a sum of the histogram. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', 'I am grateful to many people for their help and support during the writing of this book. The biggest thanks must go to my wife Jane, my children William and Susie, and my parents, all of whose encouragement has been unstinting. I must express my thanks to my students for their interest and enthusiasm in this subject. It is always refreshing to hear students discussing how to solve vision problems in tutorials and great to hear their solutions to problems, which are often different and sometimes better than my own. I thank my colleagues, in particular Arthur Hughes, Jeremy Jones and Hilary McDonald, for their encouragement and support. \\n', 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n', \"Computer vision is the automated analysis of images and videos by computers to understand the world. It's inspired by human vision, but the complexity of this task becomes apparent when we realize that our visual system makes it seem intuitive. Despite its challenges, computer vision is essential in various applications, from image recognition and object detection to autonomous vehicles and medical imaging.\", 'This edition was first published in 2014 by John Wiley & Sons Ltd. The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom. For details on global editorial offices, customer services, and permissions to reuse copyrighted material, visit www.wiley.com. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher. Wiley also publishes books in various electronic formats. Some content may not be available in electronic books. The publisher is not associated with any product or vendor mentioned in this book. The publisher and author make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. If professional advice is required, consult a competent professional.  ISBN 9781118848456. \\n']\n"
          ]
        }
      ]
    }
  ]
}